{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bipartite"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "cuda = torch.device('cuda') \n",
    "r = 8\n",
    "x = torch.rand((16,128,128,128)).to(cuda)\n",
    "y = F.avg_pool2d(x, r, r)\n",
    "\n",
    "x_shape = x.shape\n",
    "B,C,W,H = x_shape\n",
    "y_shape = y.shape\n",
    "By,Cy,Wy,Hy = y_shape\n",
    "\n",
    "def flat_nodes(x,shape):\n",
    "  B,C,W,H = shape\n",
    "  x = x.reshape((-1,C,H*W))#.contiguous()\n",
    "  x = x.transpose(1,2)#.contiguous()\n",
    "  x = x.reshape((B*H*W,C))#.contiguous()\n",
    "  return x\n",
    "\n",
    "def unflat_nodes(x,shape):\n",
    "  B,C,W,H = shape\n",
    "\n",
    "  x = x.reshape((B,H*W,C))\n",
    "  x = x.transpose(1,2)\n",
    "  x = x.reshape((-1,C,H,W))\n",
    "  return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.29327917098999023 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from torch_geometric.nn import knn\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "x_f = flat_nodes(x,x_shape)\n",
    "#print(x.shape)\n",
    "y_f = flat_nodes(y,y_shape)\n",
    "#print(y.shape)\n",
    "\n",
    "batches_x = torch.linspace(0,B,steps=(B*H*W),dtype=torch.int64).to(device=x.device)\n",
    "batches_y = torch.linspace(0,By,steps=(By*Hy*Wy),dtype=torch.int64).to(device=x.device)\n",
    "assign_index = knn(y_f, x_f, 9, batches_y, batches_x)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyG + Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.02605724334716797 seconds ---\n"
     ]
    }
   ],
   "source": [
    "from gcn_lib.torch_edge import DenseDilatedKnnGraph\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import time\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "dilated_knn_graph = DenseDilatedKnnGraph(9)\n",
    "\n",
    "y_f = y.reshape(B, C, -1, 1).contiguous() \n",
    "x_f = x.reshape(B, C, -1, 1).contiguous() \n",
    "edge_index = dilated_knn_graph(x_f, y_f, None)\n",
    "\n",
    "\n",
    "x_j = edge_index[0]\n",
    "x_i = edge_index[1]\n",
    "\n",
    "count_batches = torch.linspace(0,B,steps=(9*H*W*B),dtype=torch.int64).to(device=x.device)\n",
    "\n",
    "xx_j = x_j.reshape(-1) + ( count_batches  * (Hy*Wy))\n",
    "xx_i = x_i.reshape(-1) + ( count_batches  * (H*W))\n",
    "new_edge_index = torch.cat([xx_i.unsqueeze(0),xx_j.unsqueeze(0)], dim = 0)\n",
    "\n",
    "x_f = flat_nodes(x, x.shape)\n",
    "y_f = flat_nodes(y, y.shape)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2359296, 2])\n",
      "torch.Size([16, 16384, 9])\n",
      "torch.Size([16, 16384, 9])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_j = edge_index[0]\n",
    "x_i = edge_index[1]\n",
    "\n",
    "print(assign_index.t().shape)\n",
    "print(x_i.shape)\n",
    "print(x_j.shape)\n",
    "\n",
    "16*128*128*9 == 2359296\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[245760,   3982],\n",
      "        [245760,   3916],\n",
      "        [245760,   4024],\n",
      "        [245760,   3840],\n",
      "        [245760,   3881],\n",
      "        [245760,   3846],\n",
      "        [245760,   3999],\n",
      "        [245760,   3913],\n",
      "        [245760,   4034]], device='cuda:0')\n",
      "\n",
      "tensor([[245760,   3982],\n",
      "        [245760,   3916],\n",
      "        [245760,   4024],\n",
      "        [245760,   3840],\n",
      "        [245760,   3881],\n",
      "        [245760,   3913],\n",
      "        [245760,   3846],\n",
      "        [245760,   3999],\n",
      "        [245760,   4034]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "start = (B-1)*H*W*9\n",
    "end = start+9\n",
    "print(assign_index.t()[start:end])\n",
    "print()\n",
    "print(new_edge_index.t()[start:end])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "cuda = torch.device('cuda') \n",
    "x = torch.rand((16,128,128,128)).to(cuda)\n",
    "\n",
    "\n",
    "def flat_nodes(x,shape):\n",
    "  B,C,W,H = shape\n",
    "  x = x.reshape((-1,C,H*W))#.contiguous()\n",
    "  x = x.transpose(1,2)#.contiguous()\n",
    "  x = x.reshape((B*H*W,C))#.contiguous()\n",
    "  return x\n",
    "\n",
    "def unflat_nodes(x,shape):\n",
    "  B,C,W,H = shape\n",
    "\n",
    "  x = x.reshape((B,H*W,C))\n",
    "  x = x.transpose(1,2)\n",
    "  x = x.reshape((-1,C,H,W))\n",
    "  return x\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 11.07405948638916 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from torch_geometric.nn import knn_graph\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "x_f = flat_nodes(x,x_shape)\n",
    "\n",
    "batches_x = torch.linspace(0,B,steps=(B*H*W),dtype=torch.int64).to(device=x.device)\n",
    "assign_index = knn_graph(x_f, 9, batches_x)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyG + Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gcn_lib.torch_edge import DenseDilatedKnnGraph\n",
    "dilated_knn_graph = DenseDilatedKnnGraph(9)\n",
    "x_f = x.reshape(B, C, -1, 1).contiguous()\n",
    "edge_index = dilated_knn_graph(x_f, None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_j = edge_index[0]\n",
    "x_i = edge_index[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   0,  694,  713, 1552, 3460, 1767, 1068,  272, 1572])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_j[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: an illegal memory access was encountered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 38\u001b[0m\n\u001b[1;32m     35\u001b[0m x_i \u001b[39m=\u001b[39m edge_index[\u001b[39m1\u001b[39m]\n\u001b[1;32m     37\u001b[0m count_batches \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mlinspace(\u001b[39m0\u001b[39m,B,steps\u001b[39m=\u001b[39m(\u001b[39m9\u001b[39m\u001b[39m*\u001b[39mH\u001b[39m*\u001b[39mW\u001b[39m*\u001b[39mB),dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mint64)\n\u001b[0;32m---> 38\u001b[0m count_batches \u001b[39m=\u001b[39m count_batches\u001b[39m.\u001b[39;49mto(cuda)\n\u001b[1;32m     40\u001b[0m xx_j \u001b[39m=\u001b[39m x_j\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m+\u001b[39m ( count_batches  \u001b[39m*\u001b[39m (H\u001b[39m*\u001b[39mW))\n\u001b[1;32m     41\u001b[0m xx_i \u001b[39m=\u001b[39m x_i\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m+\u001b[39m ( count_batches  \u001b[39m*\u001b[39m (H\u001b[39m*\u001b[39mW))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: an illegal memory access was encountered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "from gcn_lib.torch_edge import DenseDilatedKnnGraph\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import time\n",
    "\n",
    "cuda = torch.device('cuda') \n",
    "x = torch.rand((16,128,64,64)).to(cuda)\n",
    "\n",
    "\n",
    "def flat_nodes(x,shape):\n",
    "  B,C,W,H = shape\n",
    "  x = x.reshape((-1,C,H*W))#.contiguous()\n",
    "  x = x.transpose(1,2)#.contiguous()\n",
    "  x = x.reshape((B*H*W,C))#.contiguous()\n",
    "  return x\n",
    "\n",
    "def unflat_nodes(x,shape):\n",
    "  B,C,W,H = shape\n",
    "\n",
    "  x = x.reshape((B,H*W,C))\n",
    "  x = x.transpose(1,2)\n",
    "  x = x.reshape((-1,C,H,W))\n",
    "  return x\n",
    "\n",
    "\n",
    "dilated_knn_graph = DenseDilatedKnnGraph(9)\n",
    "start_time = time.time()\n",
    "\n",
    "B,C,W,H = x.shape\n",
    "x_f = x.reshape(B, C, -1, 1)#.contiguous() \n",
    "edge_index = dilated_knn_graph(x_f, None, None)\n",
    "\n",
    "\n",
    "x_j = edge_index[0]\n",
    "x_i = edge_index[1]\n",
    "\n",
    "count_batches = torch.linspace(0,B,steps=(9*H*W*B),dtype=torch.int64)\n",
    "count_batches = count_batches.to(cuda)\n",
    "\n",
    "xx_j = x_j.reshape(-1) + ( count_batches  * (H*W))\n",
    "xx_i = x_i.reshape(-1) + ( count_batches  * (H*W))\n",
    "new_edge_index = torch.cat([xx_i.unsqueeze(0),xx_j.unsqueeze(0)], dim = 0)\n",
    "\n",
    "x_f = flat_nodes(x, x.shape)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 16384, 9])\n",
      "torch.Size([16, 16384, 9])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_j = edge_index[0]\n",
    "x_i = edge_index[1]\n",
    "\n",
    "#print(assign_index.t().shape)\n",
    "print(x_i.shape)\n",
    "print(x_j.shape)\n",
    "\n",
    "16*128*128*9 == 2359296"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "262144"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "16*128*128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[245760, 245760],\n",
      "        [245760, 254816],\n",
      "        [245760, 260964],\n",
      "        [245760, 259659],\n",
      "        [245760, 251757],\n",
      "        [245760, 257526],\n",
      "        [245760, 259117],\n",
      "        [245760, 254731],\n",
      "        [245760, 247671]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(262143)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = (B-1)*H*W*9\n",
    "end = start+9\n",
    "\"\"\" print(assign_index.t()[start:end])\n",
    "print() \"\"\"\n",
    "print(new_edge_index.t()[start:end])\n",
    "torch.max(new_edge_index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
