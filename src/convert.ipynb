{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bipartite"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "cuda = torch.device('cuda') \n",
    "r = 8\n",
    "x = torch.rand((16,128,128,128)).to(cuda)\n",
    "y = F.avg_pool2d(x, r, r)\n",
    "\n",
    "x_shape = x.shape\n",
    "B,C,W,H = x_shape\n",
    "y_shape = y.shape\n",
    "By,Cy,Wy,Hy = y_shape\n",
    "\n",
    "def flat_nodes(x,shape):\n",
    "  B,C,W,H = shape\n",
    "  x = x.reshape((-1,C,H*W))#.contiguous()\n",
    "  x = x.transpose(1,2)#.contiguous()\n",
    "  x = x.reshape((B*H*W,C))#.contiguous()\n",
    "  return x\n",
    "\n",
    "def unflat_nodes(x,shape):\n",
    "  B,C,W,H = shape\n",
    "\n",
    "  x = x.reshape((B,H*W,C))\n",
    "  x = x.transpose(1,2)\n",
    "  x = x.reshape((-1,C,H,W))\n",
    "  return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.29327917098999023 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from torch_geometric.nn import knn\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "x_f = flat_nodes(x,x_shape)\n",
    "#print(x.shape)\n",
    "y_f = flat_nodes(y,y_shape)\n",
    "#print(y.shape)\n",
    "\n",
    "batches_x = torch.linspace(0,B,steps=(B*H*W),dtype=torch.int64).to(device=x.device)\n",
    "batches_y = torch.linspace(0,By,steps=(By*Hy*Wy),dtype=torch.int64).to(device=x.device)\n",
    "assign_index = knn(y_f, x_f, 9, batches_y, batches_x)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyG + Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.02605724334716797 seconds ---\n"
     ]
    }
   ],
   "source": [
    "from gcn_lib.torch_edge import DenseDilatedKnnGraph\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import time\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "dilated_knn_graph = DenseDilatedKnnGraph(9)\n",
    "\n",
    "y_f = y.reshape(B, C, -1, 1).contiguous() \n",
    "x_f = x.reshape(B, C, -1, 1).contiguous() \n",
    "edge_index = dilated_knn_graph(x_f, y_f, None)\n",
    "\n",
    "\n",
    "x_j = edge_index[0]\n",
    "x_i = edge_index[1]\n",
    "\n",
    "count_batches = torch.linspace(0,B,steps=(9*H*W*B),dtype=torch.int64).to(device=x.device)\n",
    "\n",
    "xx_j = x_j.reshape(-1) + ( count_batches  * (Hy*Wy))\n",
    "xx_i = x_i.reshape(-1) + ( count_batches  * (H*W))\n",
    "new_edge_index = torch.cat([xx_i.unsqueeze(0),xx_j.unsqueeze(0)], dim = 0)\n",
    "\n",
    "x_f = flat_nodes(x, x.shape)\n",
    "y_f = flat_nodes(y, y.shape)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2359296, 2])\n",
      "torch.Size([16, 16384, 9])\n",
      "torch.Size([16, 16384, 9])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_j = edge_index[0]\n",
    "x_i = edge_index[1]\n",
    "\n",
    "print(assign_index.t().shape)\n",
    "print(x_i.shape)\n",
    "print(x_j.shape)\n",
    "\n",
    "16*128*128*9 == 2359296\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[245760,   3982],\n",
      "        [245760,   3916],\n",
      "        [245760,   4024],\n",
      "        [245760,   3840],\n",
      "        [245760,   3881],\n",
      "        [245760,   3846],\n",
      "        [245760,   3999],\n",
      "        [245760,   3913],\n",
      "        [245760,   4034]], device='cuda:0')\n",
      "\n",
      "tensor([[245760,   3982],\n",
      "        [245760,   3916],\n",
      "        [245760,   4024],\n",
      "        [245760,   3840],\n",
      "        [245760,   3881],\n",
      "        [245760,   3913],\n",
      "        [245760,   3846],\n",
      "        [245760,   3999],\n",
      "        [245760,   4034]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "start = (B-1)*H*W*9\n",
    "end = start+9\n",
    "print(assign_index.t()[start:end])\n",
    "print()\n",
    "print(new_edge_index.t()[start:end])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "cuda = torch.device('cuda') \n",
    "x = torch.rand((16,128,64,64))#.to(cuda)\n",
    "\n",
    "x_shape = x.shape\n",
    "B,C,W,H = x_shape\n",
    "\n",
    "def flat_nodes(x,shape):\n",
    "  B,C,W,H = shape\n",
    "  x = x.reshape((-1,C,H*W)).contiguous()\n",
    "  x = x.transpose(1,2).contiguous()\n",
    "  x = x.reshape((B*H*W,C)).contiguous()\n",
    "  return x\n",
    "\n",
    "def unflat_nodes(x,shape):\n",
    "  B,C,W,H = shape\n",
    "\n",
    "  x = x.reshape((B,H*W,C))\n",
    "  x = x.transpose(1,2)\n",
    "  x = x.reshape((-1,C,H,W))\n",
    "  return x\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 11.07405948638916 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from torch_geometric.nn import knn_graph\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "x_f = flat_nodes(x,x_shape)\n",
    "\n",
    "batches_x = torch.linspace(0,B,steps=(B*H*W),dtype=torch.int64).to(device=x.device)\n",
    "assign_index = knn_graph(x_f, 9, batches_x)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyG + Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gcn_lib.torch_edge import DenseDilatedKnnGraph\n",
    "dilated_knn_graph = DenseDilatedKnnGraph(9)\n",
    "x_f = x.reshape(B, C, -1, 1).contiguous()\n",
    "edge_index = dilated_knn_graph(x_f, None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_j = edge_index[0]\n",
    "x_i = edge_index[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   0,  694,  713, 1552, 3460, 1767, 1068,  272, 1572])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_j[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: CUBLAS_STATUS_EXECUTION_FAILED when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/scratch/GBIC/src/convert.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f7370616461726f2d6465762d636f6e7461696e65722e312e69637a6f7970756d77686572307177397a3267737163797232222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6873736833227d7d/scratch/GBIC/src/convert.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f7370616461726f2d6465762d636f6e7461696e65722e312e69637a6f7970756d77686572307177397a3267737163797232222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6873736833227d7d/scratch/GBIC/src/convert.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m x_f \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mreshape(B, C, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mcontiguous() \n\u001b[0;32m---> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f7370616461726f2d6465762d636f6e7461696e65722e312e69637a6f7970756d77686572307177397a3267737163797232222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6873736833227d7d/scratch/GBIC/src/convert.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m edge_index \u001b[39m=\u001b[39m dilated_knn_graph(x_f, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f7370616461726f2d6465762d636f6e7461696e65722e312e69637a6f7970756d77686572307177397a3267737163797232222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6873736833227d7d/scratch/GBIC/src/convert.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m x_j \u001b[39m=\u001b[39m edge_index[\u001b[39m0\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f7370616461726f2d6465762d636f6e7461696e65722e312e69637a6f7970756d77686572307177397a3267737163797232222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6873736833227d7d/scratch/GBIC/src/convert.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m x_i \u001b[39m=\u001b[39m edge_index[\u001b[39m1\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/scratch/GBIC/src/gcn_lib/torch_edge.py:160\u001b[0m, in \u001b[0;36mDenseDilatedKnnGraph.forward\u001b[0;34m(self, x, y, relative_pos)\u001b[0m\n\u001b[1;32m    158\u001b[0m     x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mnormalize(x, p\u001b[39m=\u001b[39m\u001b[39m2.0\u001b[39m, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    159\u001b[0m     \u001b[39m####\u001b[39;00m\n\u001b[0;32m--> 160\u001b[0m     edge_index \u001b[39m=\u001b[39m dense_knn_matrix(x, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mk \u001b[39m*\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, relative_pos)\n\u001b[1;32m    161\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dilated(edge_index)\n",
      "File \u001b[0;32m/scratch/GBIC/src/gcn_lib/torch_edge.py:73\u001b[0m, in \u001b[0;36mdense_knn_matrix\u001b[0;34m(x, k, relative_pos)\u001b[0m\n\u001b[1;32m     71\u001b[0m start_idx \u001b[39m=\u001b[39m n_part \u001b[39m*\u001b[39m i\n\u001b[1;32m     72\u001b[0m end_idx \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(n_points, n_part \u001b[39m*\u001b[39m (i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m))\n\u001b[0;32m---> 73\u001b[0m dist \u001b[39m=\u001b[39m part_pairwise_distance(x\u001b[39m.\u001b[39;49mdetach(), start_idx, end_idx)\n\u001b[1;32m     74\u001b[0m \u001b[39mif\u001b[39;00m relative_pos \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     75\u001b[0m     dist \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m relative_pos[:, start_idx:end_idx]\n",
      "File \u001b[0;32m/scratch/GBIC/src/gcn_lib/torch_edge.py:34\u001b[0m, in \u001b[0;36mpart_pairwise_distance\u001b[0;34m(x, start_idx, end_idx)\u001b[0m\n\u001b[1;32m     32\u001b[0m x_part \u001b[39m=\u001b[39m x[:, start_idx:end_idx]\n\u001b[1;32m     33\u001b[0m x_square_part \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msum(torch\u001b[39m.\u001b[39mmul(x_part, x_part), dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, keepdim\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> 34\u001b[0m x_inner \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m2\u001b[39m\u001b[39m*\u001b[39mtorch\u001b[39m.\u001b[39;49mmatmul(x_part, x\u001b[39m.\u001b[39;49mtranspose(\u001b[39m2\u001b[39;49m, \u001b[39m1\u001b[39;49m))\n\u001b[1;32m     35\u001b[0m x_square \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msum(torch\u001b[39m.\u001b[39mmul(x, x), dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, keepdim\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     36\u001b[0m \u001b[39mreturn\u001b[39;00m x_square_part \u001b[39m+\u001b[39m x_inner \u001b[39m+\u001b[39m x_square\u001b[39m.\u001b[39mtranspose(\u001b[39m2\u001b[39m, \u001b[39m1\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: CUBLAS_STATUS_EXECUTION_FAILED when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`"
     ]
    }
   ],
   "source": [
    "from gcn_lib.torch_edge import DenseDilatedKnnGraph\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import time\n",
    "\n",
    "dilated_knn_graph = DenseDilatedKnnGraph(9)\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "x_f = x.reshape(B, C, -1, 1).contiguous() \n",
    "edge_index = dilated_knn_graph(x_f, None, None)\n",
    "\n",
    "\n",
    "x_j = edge_index[0]\n",
    "x_i = edge_index[1]\n",
    "\n",
    "\n",
    "count_batches = torch.linspace(0,B,steps=(9*H*W*B),dtype=torch.int64).to(device=x.device)\n",
    "\n",
    "xx_j = x_j.reshape(-1) + ( count_batches  * (H*W))\n",
    "xx_i = x_i.reshape(-1) + ( count_batches  * (H*W))\n",
    "new_edge_index = torch.cat([xx_i.unsqueeze(0),xx_j.unsqueeze(0)], dim = 0)\n",
    "\n",
    "x_f = flat_nodes(x, x.shape)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 16384, 9])\n",
      "torch.Size([16, 16384, 9])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_j = edge_index[0]\n",
    "x_i = edge_index[1]\n",
    "\n",
    "#print(assign_index.t().shape)\n",
    "print(x_i.shape)\n",
    "print(x_j.shape)\n",
    "\n",
    "16*128*128*9 == 2359296"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "262144"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "16*128*128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4294967295, 45253477951859],\n",
      "        [140603461348672, 140603461348672],\n",
      "        [         0,          0],\n",
      "        [         0,          0],\n",
      "        [         0,          0],\n",
      "        [140603461348800, 93945397926560],\n",
      "        [         0,         97],\n",
      "        [         0,          0],\n",
      "        [140603461348656, 140603461348656]], device='cuda:0')\n",
      "\n",
      "tensor([[140603461348640, 140603461348640],\n",
      "        [         0,          0],\n",
      "        [93945397936032, 93944490311536],\n",
      "        [140603461348672, 93945397934944],\n",
      "        [93945397936032, 93945397926560],\n",
      "        [140603461348672, 140603461348672],\n",
      "        [         0,          0],\n",
      "        [         0,          0],\n",
      "        [         0,          0]], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(     16386, device='cuda:0')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = (B-1)*H*W*9\n",
    "end = start+9\n",
    "print(assign_index.t()[start:end])\n",
    "print()\n",
    "print(new_edge_index.t()[start:end])\n",
    "torch.max(assign_index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (main, Nov  4 2022, 13:48:29) [GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
